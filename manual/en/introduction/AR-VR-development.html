<!DOCTYPE html>
<html lang="en">
  <head>
    <title>AR/VR Development — Soft8Soft</title>
    <meta charset="utf-8">
    <meta name="description" content="Learn how you can enable Augmented Reality (AR) and Virtual Reality (VR) experience for your Verge3D applications."/>
    <base href="../../../" />
    <script src="page.js"></script>
    <link type="text/css" rel="stylesheet" href="page.css" />
  </head>
  <body><article>

    <h1>AR/VR Development</h1>

    <p>
      Verge3D allows for creating web-based Augmented Reality (AR) and Virtual Reality (VR) experiences running on top of the browser technology called *WebXR* (eXtended Reality on the Web). In addition to that you can use USDZ format and Apple AR Quick Look technology to preview your models in AR mode on iPhones and iPads.
    </p>

    <iframe class="video-480p" src="https://www.youtube.com/embed/92AMh4vV4zw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

    <h2>Contents</h2>

    [contents]


    [anchor:virtual_reality]

    <h2>Virtual Reality (VR)</h2>


    [anchor:Setting_up_VR]

    <h3>Setting Up</h3>

    <p>
      HTC VIVE and Meta Quest devices should work with WebXR out of the box. Use Google Chrome browser for PC-connected devices such as HTC VIVE Pro. Use the browser which comes with your headset in case of standalone devices, e.g run your VR apps in Quest Browser on Meta Quest 1-3.
    </p>

    <p class="note">
      WebXR requires a secure context. Verge3D apps must be served over HTTPS, or from the localhost URL.
    </p>


    [anchor:Creating_VR_Apps]

    <h3>Creating VR Apps</h3>

    <p>
      The VR mode can be checked with <a href="manual/en/puzzles/AR_VR.html#check_vr_mode">check VR mode</a> and set up using <a href="manual/en/puzzles/AR_VR.html#enter_vr_mode">enter VR mode</a> puzzle.
    </p>

    <img src="files/ar-vr-development/minimal-vr-puzzles.jpg" alt="Minimal VR puzzles">

    <p>
      Interaction with 3D objects is performed by using the gaze-based reticle pointer automatically provided for VR devices <i>without controllers</i> (such as cardboards).
    </p>

    <img src="files/ar-vr-development/gaze-based-reticle-pointer.jpg" alt="Gaze-based VR reticle pointer">

    <p>For VR devices <i>with controllers</i>, interaction is performed by the virtual ray casted from the controllers.</p>

    <img src="files/ar-vr-development/google-daydream-vr-controller.jpg" alt="Controller-based VR ray">

    <p>
      You can use the standard <a href="manual/en/puzzles/Events.html#when_hovered">when hovered</a> or <a href="manual/en/puzzles/Events.html#when_clicked">when clicked</a> puzzles to capture user events as well as VR-specific <a href="manual/en/puzzles/AR_VR.html#session_event">on session event</a>.
    </p>


    [anchor:how_to_move_in_vr_mode]

    <h3>How to move in VR mode</h3>

    <p>
      Upon entering the VR mode, you will get the special stereo camera which will be attached to a VR headset. It means you can't use any controls or Puzzles to change the camera's position (or orientation). The only way to move the camera in VR is parenting it to some other object (e.g character) and moving this object instead. Check out the <a href="manual/en/puzzles/AR_VR.html#xr_camera_control_object">camera control object</a> for more info.
    </p>

    <p>
      In general, you will need to specify the movements by Puzzles or JavaScript, e.g by using a character object and some physics which prevents the character to move beyond the scene bounds (or obstacles). However, if you use the *sitting or standing* VR positioning mode, there is a Puzzles library called <a href="manual/en/puzzles/Library.html#vr_controls">VR Controls</a> which can make the things a lot easier.
    </p>

    [demo:virtual_reality]



    [anchor:augmented_reality]

    <h2>Augmented Reality (AR)</h2>


    [anchor:Setting_up_AR]

    <h3>Setting Up</h3>

    <p>You can run your Verge3D-based augmented reality applications on mobile devices with Android or iOS/iPadOS operating systems.</p>

    <p class="note">
      WebXR requires a secure context. Verge3D apps must be served over HTTPS, or from the localhost URL.
    </p>

    <h4>Android</h4>

    <p>To enable augmented reality, you need an Android device which supports <a href="https://developers.google.com/ar/discover/supported-devices" target="_blank">ARCore technology</a> and latest Google Chrome browser. You also need to install Google Play Services for AR. The installation of this package is prompted automatically upon entering AR mode for the first time, if not pre-installed.</p>

    <img src="files/ar-vr-development/google-play-services-for-ar.jpg" alt="Installing Google Play Services for AR" style="max-width: 720px">

    <h4>iOS/iPadOS</h4>

    <p>
      For iPhones/iPads you have two choices:
    </p>

    <ol>
      <li>install *WebXR Viewer* browser</li>
      <li>preview assets in *USDZ* format using the conventional Safari browser</li>
    </ol>

    <p>
      Mozilla's WebXR Viewer is a Firefox-based browser application which supports the AR technology on Apple devices (starting from iPhone 6s). This app is <a href="https://apps.apple.com/us/app/webxr-viewer/id1295998056" target="_blank">available</a> from the Apple App Store. This solution has an advantage, that you can use the same WebXR technology (as well as Puzzles logic) that you use to run AR on Android devices. The disadvantage is obvious — you (as well as your users) should install WebXR Viewer browser manually.
    </p>

    <p>
      With USDZ assets, you can use the <a href="https://developer.apple.com/augmented-reality/quick-look/" target="_blank">Apple AR Quick Look</a> technology to run simplified augmented reality experience in the default Safari browser. This approach requires you to use completely different rendering engine integrated in iOS, as such you can't make complex materials or use Puzzles logic for your apps running in AR mode.
    </p>


    [anchor:creating_ar_apps_webxr]

    <h3>Creating WebXR-based AR apps (Android, WebXR Viewer)</h3>

    <p>
      The AR mode can be set up for any Verge3D app using the <a href="manual/en/puzzles/AR_VR.html#enter_ar_mode">enter AR mode</a> puzzle.
    </p>

    <img src="files/ar-vr-development/minimal-ar-puzzles.jpg" alt="Minmal AR puzzles" style="max-width: 819px">

    <p>
      Upon entering AR mode you will be able to position your 3D content in the "real" coordinate system, which is aligned with your mobile device. In addition to that, you can detect horizontal surfaces (tables, shelves, floor etc) by using the <a href="manual/en/puzzles/AR_VR.html#ar_hit_test">detect horizontal surface AR</a> puzzle.
    </p>

    <!-- enabling transparency for AR is a hack for WebXR Viewer -->

    <p>
      Also, to see the real environment through your 3D canvas, you should enable the *transparent background* option in the <a href="manual/en/puzzles/Initialization.html#configure_application">configure application</a> puzzle.
    </p>

    <img src="files/ar-vr-development/transparent-background-puzzle.jpg" alt="Enabling background transparency in puzzles">

    [demo:augmented_reality]


    [anchor:creating_ar_apps_usdz]

    <h3>Creating USDZ-based AR apps</h3>

    <p>
      To enter AR Quick Look mode you need to create USDZ asset first. To do this, you can export your scene (or a single model) in runtime (on the fly) or use your favorite modelling suite to make it ahead of time.
    </p>

    <h4>Preparing USDZ asset in runtime</h4>

    <p>
      This approach is based on using <a href="manual/en/puzzles/Scenes.html#export_to_usdz">export to USDZ</a> puzzle to generate USDZ (see Puzzles snippet below).
    </p>

    <h4>Preparing USDZ asset in modelling suites</h4>

    <p>
      USDZ export supported natively in Blender (starting from version 3.5), 3ds Max (requires <a href="https://knowledge.autodesk.com/support/3ds-max/learn-explore/caas/CloudHelp/cloudhelp/2022/ENU/3dsMax-USD/files/GUID-04F1DF51-0079-4DF8-8457-5AD12B6C0673-html.html" target="_blank">USD extension</a> to be installed), and Maya.
    </p>

    <p class="note">
      USDZ is different from USD, being a container which combines USD models with media data, such as PNG, JPEG, MP3. Thus, modelling suites which able to export to USD not necessary support USDZ.
    </p>

    <p>
      If you use macOS/iOS/iPadOS, there are plenty of <a href="https://developer.apple.com/augmented-reality/tools/" target="_blank">tools</a> available on Apple website to convert your models stored in OBJ/FBX/glTF/USD formats to USDZ.
    </p>

    <h4>Loading USDZ</h4>

    <p>
      To preview USDZ asset, exported by the modelling suite or some other tool, you need to create an HTML link with the image inside it:
    </p>

    <code>
    &lt;a id=&quot;enter_AR_button&quot; rel=&quot;ar&quot; href=&quot;model.usdz&quot;&gt;
      &lt;img src=&quot;media/enter_AR_button.png&quot;&gt;
    &lt;/a&gt;
    </code>

    <p>
      The link should reference a USDZ model asset, e.g <em>model.usdz</em>. The image should reference picture which shows some button with icon or text, e.g "Enter AR". In the example above, the image located at <em>media/enter_AR_button.png</em> inside the application directory.
    </p>

    <p>
      When the user clicks on such link on Apple device, the system will detect USDZ asset referenced by the link and open an AR Quick Look mode so that you can position the model in the real world:
    </p>

    <img src="files/ar-vr-development/ar-quick-look.jpg" alt="Apple AR Quick Look" style="max-width: 310px">

    <p>
      With Puzzles, the same link can be created on demand:
    </p>

    <img src="files/ar-vr-development/usdz-puzzles-static.jpg" alt="Creating USDZ link using puzzles">

    <p>
      To generate and load USDZ assets in runtime use the following code:
    </p>

    <img src="files/ar-vr-development/usdz-puzzles-dynamic.jpg" alt="Creating USDZ asset in runtime using puzzles">

    <p>
      Check out the differences — we used *export to USDZ* puzzle here and assigned additional *download* attribute to the link.
    </p>

    [demo:augmented_reality]


    [anchor:how_to_move_in_ar_mode]

    <h3>How to move in AR mode</h3>

    <p>
      Upon entering the AR mode, you will get the special camera which will be attached to the phone (or the AR headset). It means you can't use any controls or Puzzles to change the camera's position (or orientation). The only way to move the camera in AR is parenting it to some other object and moving this object instead. Check out the <a href="manual/en/puzzles/AR_VR.html#xr_camera_control_object">camera control object</a> for more info.
    </p>


    [anchor:chrome_debugging]

    <h2>Chrome Debugging</h2>

    <p>
      For faster iterations during development of WebXR-based apps (but not USDZ-based), you can use Chrome's <a href="manual/en/introduction/Testing-Mobile-Browsers.html#Port_Forwarding">port forwarding</a> feature to run your AR or VR app in mobile browser. This will save you from re-uploading it to a remote web server each time.
    </p>


    [anchor:whats_next]

    <h2>What's Next</h2>

    <p>
      To find out how to script your AR/VR app with Puzzles, read the <a href="manual/en/puzzles/AR_VR.html">following</a> section. Also, check out the <a href="manual/en/introduction/Physics-Guide.html">Physics Guide</a > if you're going to simulate a realistic virtual environment with colliding objects and/or character.
    </p>

    [demo:snowballs_vr]


    <h3>Got Questions?</h3>

    <p>Feel free to ask on the <a href="https://www.soft8soft.com/forums/" target="_blank">forums</a>!</p>

  </article></body>
</html>
